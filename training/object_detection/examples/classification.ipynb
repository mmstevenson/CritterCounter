{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLT Classification example usecase\n",
    "\n",
    "#### This notebook shows an example use case for classification using the Transfer Learning Toolkit. **_It is not optimized for accuracy._**\n",
    "\n",
    "0. [Set up env variables](#head-0)\n",
    "1. [Prepare dataset and pretrained model](#head-1)<br>\n",
    "    1.1 [Split the dataset into train/test/val](#head-1-1)<br>\n",
    "    1.2 [Download pre-trained model](#head-1-2)<br>\n",
    "2. [Provide training specfication](#head-2)\n",
    "3. [Run TLT training](#head-3)\n",
    "4. [Evaluate trained models](#head-4)\n",
    "5. [Prune trained models](#head-5)\n",
    "6. [Retrain pruned models](#head-6)\n",
    "7. [Testing the model](#head-7)\n",
    "8. [Visualize inferences](#head-8)\n",
    "0. [Export and Deploy!](#head-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup env variables <a class=\"anchor\" id=\"head-0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace the **$API_KEY** with your api key on **ngc.nvidia.com**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env USER_EXPERIMENT_DIR=/workspace/tlt-experiments\n",
    "%env DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/data\n",
    "%env SPECS_DIR=/workspace/examples/specs\n",
    "%env API_KEY=$API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare datasets and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the pascal VOC dataset for the tutorial. To find more details please visit \n",
    "http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit. Please download the dataset present at http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to $DATA_DOWNLOAD_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that file is present\n",
    "import os\n",
    "DATA_DIR = os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "if not os.path.isfile(os.path.join(DATA_DIR , 'VOCtrainval_11-May-2012.tar')):\n",
    "    print('tar file for dataset not found. Please download.')\n",
    "else:\n",
    "    print('Found dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack \n",
    "!tar -xvf $DATA_DOWNLOAD_DIR/VOCtrainval_11-May-2012.tar -C $DATA_DOWNLOAD_DIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "!ls $DATA_DOWNLOAD_DIR/VOCdevkit/VOC2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Split the dataset into train/val/test <a class=\"anchor\" id=\"head-1-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pascal VOC Dataset is converted to our format (for classification) and then to train/val/test in the next two blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as join_path\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "DATA_DIR=os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "source_dir = join_path(DATA_DIR, \"VOCdevkit/VOC2012\")\n",
    "target_dir = join_path(DATA_DIR, \"formatted\")\n",
    "\n",
    "\n",
    "suffix = '_trainval.txt'\n",
    "classes_dir = join_path(source_dir, \"ImageSets\", \"Main\")\n",
    "images_dir = join_path(source_dir, \"JPEGImages\")\n",
    "classes_files = glob.glob(classes_dir+\"/*\"+suffix)\n",
    "for file in classes_files:\n",
    "    # get the filename and make output class folder\n",
    "    classname = os.path.basename(file)\n",
    "    if classname.endswith(suffix):\n",
    "        classname = classname[:-len(suffix)]\n",
    "        target_dir_path = join_path(target_dir, classname)\n",
    "        if not os.path.exists(target_dir_path):\n",
    "            os.makedirs(target_dir_path)\n",
    "    else:\n",
    "        continue\n",
    "    print(classname)\n",
    "\n",
    "\n",
    "    with open(file) as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "\n",
    "    for line in content:\n",
    "        tokens = re.split('\\s+', line)\n",
    "        if tokens[1] == '1':\n",
    "            # copy this image into target dir_path\n",
    "            target_file_path = join_path(target_dir_path, tokens[0] + '.jpg')\n",
    "            src_file_path = join_path(images_dir, tokens[0] + '.jpg')\n",
    "            shutil.copyfile(src_file_path, target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from random import shuffle\n",
    "\n",
    "DATA_DIR=os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "SOURCE_DIR=join_path(DATA_DIR, 'formatted')\n",
    "TARGET_DIR=os.path.join(DATA_DIR,'split')\n",
    "# list dir\n",
    "dir_list = os.walk(SOURCE_DIR).next()[1]\n",
    "# for each dir, create a new dir in split\n",
    "for dir_i in dir_list:\n",
    "        # print(\"Splitting {}\".format(dir_i))\n",
    "        newdir_train = os.path.join(TARGET_DIR, 'train', dir_i)\n",
    "        newdir_val = os.path.join(TARGET_DIR, 'val', dir_i)\n",
    "        newdir_test = os.path.join(TARGET_DIR, 'test', dir_i)\n",
    "        \n",
    "        if not os.path.exists(newdir_train):\n",
    "                os.makedirs(newdir_train)\n",
    "        if not os.path.exists(newdir_val):\n",
    "                os.makedirs(newdir_val)\n",
    "        if not os.path.exists(newdir_test):\n",
    "                os.makedirs(newdir_test)\n",
    "\n",
    "        img_list = glob.glob(os.path.join(SOURCE_DIR, dir_i, '*.jpg'))\n",
    "        # shuffle data\n",
    "        shuffle(img_list)\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'train', dir_i))\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7), int(len(img_list)*0.8)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'val', dir_i))\n",
    "                \n",
    "        for j in range(int(len(img_list)*0.8), len(img_list)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'test', dir_i))\n",
    "                \n",
    "print('Done splitting dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $DATA_DOWNLOAD_DIR/split/test/cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download pretrained models <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the list of available models. Find your **ORG** and **TEAM** on ngc.nvidia.com and replace the **-o** and **-t** arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-pull -k $API_KEY -lm -o nvtltea -t iva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the resnet18 classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-pull -d $USER_EXPERIMENT_DIR -k $API_KEY  -m tlt_iva_classification_resnet18 -v 1 -o nvtltea -t iva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $USER_EXPERIMENT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Provide training specfication <a class=\"anchor\" id=\"head-2\"></a>\n",
    "* Training dataset\n",
    "* Validation dataset\n",
    "* Pre-trained models\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $SPECS_DIR/classification_spec.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run TLT training <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Provide the sample spec file and the output directory location for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create an output dir')\n",
    "!mkdir $USER_EXPERIMENT_DIR/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model checkpoints and logs:')\n",
    "print('---------------------')\n",
    "!ls -l $USER_EXPERIMENT_DIR/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please change the **train_dataset_path, val_dataset_path, pretrained_model_path** in the spec file below if these values are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check spec file\")\n",
    "\n",
    "!cat $SPECS_DIR/classification_spec.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-train classification -e $SPECS_DIR/classification_spec.cfg -r $USER_EXPERIMENT_DIR/output -k $API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate trained models <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-evaluate classification -d $DATA_DOWNLOAD_DIR/split/test \\\n",
    "                               -pm $USER_EXPERIMENT_DIR/output/weights/resnet_001.tlt \\\n",
    "                               -b 32 -k $API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prune trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion\n",
    "* Threshold for pruning\n",
    "* Exclude prediction layer that you don't want pruned (e.g. predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-prune -pm $USER_EXPERIMENT_DIR/output/weights/resnet_001.tlt \\\n",
    "                -o $USER_EXPERIMENT_DIR/output/resnet_001_pruned \\\n",
    "                -eq union \\\n",
    "                -pth 0.7 -k $API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pruned model:')\n",
    "print('------------')\n",
    "!ls -1 $USER_EXPERIMENT_DIR/output/resnet_001_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain pruned models <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* Model needs to be re-trained to bring back accuracy after pruning\n",
    "* Specify re-training specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please change the **train_dataset_path, val_dataset_path, pretrained_model_path** in the spec file below if these values are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $SPECS_DIR/classification_retrain_spec.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-train classification -e $SPECS_DIR/classification_retrain_spec.cfg -r $USER_EXPERIMENT_DIR/output_retrain -k $API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the model! <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-evaluate classification -d $DATA_DOWNLOAD_DIR/split/test \\\n",
    "                               -pm $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_001.tlt \\\n",
    "                               -b 32 -k $API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Inferences <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the output results of our model on test images, we can use the tlt-infer tool. Note that using models trained for higher epochs will result in better results. We'll run inference on a directory of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-infer classification -m $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_001.tlt \\\n",
    "                          -k $API_KEY -b 32 -d $DATA_DOWNLOAD_DIR/split/test/person \\\n",
    "                          -cm $USER_EXPERIMENT_DIR/output_retrain/classmap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can also run inference on a single image. Uncomment the code below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tlt-infer classification -m $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_001.tlt \\\n",
    "#                          -k $API_KEY -b 32 -i $DATA_DOWNLOAD_DIR/split/test/person/2008_000032.jpg \\\n",
    "#                          -cm $USER_EXPERIMENT_DIR/output_retrain/classmap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in Getting Started Guide, this outputs a results.csv file in the same directory. We can use a simple python program to see the visualize the output of csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import os\n",
    "import csv\n",
    "from math import ceil\n",
    "\n",
    "DATA_DIR = os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "csv_path = os.path.join(DATA_DIR, 'split', 'test', 'person', 'result.csv')\n",
    "results = []\n",
    "with open(csv_path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        results.append((row[1], row[2]))\n",
    "\n",
    "w,h = 200,200\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "columns = 5\n",
    "rows = 1\n",
    "for i in range(1, columns*rows + 1):\n",
    "    ax = fig.add_subplot(rows, columns,i)\n",
    "    img = Image.open(results[i][0])\n",
    "    img = img.resize((w,h), Image.ANTIALIAS)\n",
    "    plt.imshow(img)\n",
    "    ax.set_title(results[i][1], fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export and Deploy! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-export $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_001.tlt \\\n",
    "                --input_dim 3,224,224 \\\n",
    "                -o $USER_EXPERIMENT_DIR/export/final_model.uff \\\n",
    "                --enc_key $API_KEY \\\n",
    "                --outputs predictions/Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
