{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Image Classification model for NACTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model on the species dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "# weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "# top_model_weights_path = 'fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_dataframe_path = '/data/dataframes/speciesTrain.csv'\n",
    "validation_data_dir = '/data/dataframes/speciesTest.csv'\n",
    "checkpoint_dir = '/data/ResNet50/ResNet50_20190404_species_weights.h5'\n",
    "tensorboard_dir = '/data/ResNet50/species/logs'\n",
    "nb_train_samples = 50000\n",
    "nb_validation_samples = 10000\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "# gpu_count = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the training and validation dataframes\n",
    "train_df = pd.read_csv(train_dataframe_path)\n",
    "train_df['abs_file_path'] = '/data/nacti/' + train_df['file_path']\n",
    "val_df = pd.read_csv(validation_data_dir)\n",
    "val_df['abs_file_path'] = '/data/nacti/' + val_df['file_path']\n",
    "\n",
    "# Check to ensure that the camera trap locations are disjoint\n",
    "assert len(train_df[train_df['cam_location'].isin(val_df['cam_location'].unique())]) == 0, \"Train and validation are not disjoint\"\n",
    "\n",
    "# Get the number of classes\n",
    "min(train_df['category_name'].nunique(), val_df['category_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['american_black_bear', 'bobcat', 'cougar', 'coyote',\n",
       "       'domestic_cow', 'domestic_dog', 'elk', 'gray_fox', 'moose',\n",
       "       'mule_deer', 'red_deer', 'red_fox', 'vehicle', 'white_tailed_deer',\n",
       "       'wild_turkey', 'wolf'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['category_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'american_black_bear': 0,\n",
       " 'bobcat': 1,\n",
       " 'cougar': 2,\n",
       " 'coyote': 3,\n",
       " 'domestic_cow': 4,\n",
       " 'domestic_dog': 5,\n",
       " 'elk': 6,\n",
       " 'gray_fox': 7,\n",
       " 'moose': 8,\n",
       " 'mule_deer': 9,\n",
       " 'red_deer': 10,\n",
       " 'red_fox': 11,\n",
       " 'vehicle': 12,\n",
       " 'white_tailed_deer': 13,\n",
       " 'wild_turkey': 14,\n",
       " 'wolf': 15}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{cat:i for i, cat in enumerate(train_df['category_name'].unique())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# build the MobileNetV2 network\n",
    "ResNet50 = applications.ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "model = Sequential()\n",
    "model.add(ResNet50)\n",
    "model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "# Make it a multi-gpu model if available\n",
    "# model = multi_gpu_model(model, gpus=gpu_count)\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_dir, verbose=1, save_best_only=True)\n",
    "tboard = TensorBoard(tensorboard_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 115923 images belonging to 16 classes.\n",
      "Found 31833 images belonging to 16 classes.\n",
      "{0: 1.0, 1: 1.0, 2: 1.0283833813245578, 3: 1.0, 4: 1.0, 5: 21.008403361344538, 6: 1.0, 7: 1.5780337699226763, 8: 1.639881928501148, 9: 1.0, 10: 1.0, 11: 8.19000819000819, 12: 1.0, 13: 1.1978917105893627, 14: 2.986857825567503, 15: 26.954177897574123}\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    x_col='abs_file_path', \n",
    "    y_col ='category_name', \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    val_df, \n",
    "    x_col='abs_file_path', \n",
    "    y_col ='category_name', \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "counter = Counter(train_generator.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}  \n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if max([v for k,v in class_weights.items()]) < 2:\n",
    "    class_weights = {0:1, 1:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "781/781 [==============================] - 2190s 3s/step - loss: 2.4529 - acc: 0.4260 - val_loss: 1.0841 - val_acc: 0.6276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.08408, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - 2199s 3s/step - loss: 1.5163 - acc: 0.6147 - val_loss: 0.8873 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.08408 to 0.88733, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - 2122s 3s/step - loss: 1.2651 - acc: 0.6702 - val_loss: 0.8474 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.88733 to 0.84743, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - 2071s 3s/step - loss: 1.0959 - acc: 0.7064 - val_loss: 0.7895 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84743 to 0.78951, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - 2124s 3s/step - loss: 0.9700 - acc: 0.7331 - val_loss: 0.7832 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.78951 to 0.78319, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - 2074s 3s/step - loss: 0.9098 - acc: 0.7494 - val_loss: 0.7056 - val_acc: 0.7773\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.78319 to 0.70561, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 7/25\n",
      "781/781 [==============================] - 2109s 3s/step - loss: 0.8562 - acc: 0.7653 - val_loss: 0.6561 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.70561 to 0.65613, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - 2092s 3s/step - loss: 0.7741 - acc: 0.7816 - val_loss: 0.7240 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.65613\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - 2095s 3s/step - loss: 0.7624 - acc: 0.7848 - val_loss: 0.6004 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.65613 to 0.60044, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - 1996s 3s/step - loss: 0.7265 - acc: 0.7970 - val_loss: 0.6074 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60044\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - 2063s 3s/step - loss: 0.6826 - acc: 0.8079 - val_loss: 0.6160 - val_acc: 0.8042\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.60044\n",
      "Epoch 12/25\n",
      "781/781 [==============================] - 2138s 3s/step - loss: 0.6414 - acc: 0.8151 - val_loss: 0.6212 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60044\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - 2007s 3s/step - loss: 0.6232 - acc: 0.8205 - val_loss: 0.6485 - val_acc: 0.8018\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60044\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - 1978s 3s/step - loss: 0.6257 - acc: 0.8242 - val_loss: 0.6177 - val_acc: 0.8073\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60044\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - 2127s 3s/step - loss: 0.5767 - acc: 0.8335 - val_loss: 0.5934 - val_acc: 0.8151\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.60044 to 0.59339, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - 2104s 3s/step - loss: 0.5751 - acc: 0.8339 - val_loss: 0.6194 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.59339\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - 2057s 3s/step - loss: 0.5634 - acc: 0.8380 - val_loss: 0.6073 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.59339\n",
      "Epoch 18/25\n",
      "781/781 [==============================] - 2001s 3s/step - loss: 0.5426 - acc: 0.8442 - val_loss: 0.6055 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.59339\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - 2030s 3s/step - loss: 0.5219 - acc: 0.8485 - val_loss: 0.5888 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.59339 to 0.58880, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - 2028s 3s/step - loss: 0.4940 - acc: 0.8542 - val_loss: 0.5994 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.58880\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - 2045s 3s/step - loss: 0.4914 - acc: 0.8540 - val_loss: 0.5669 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.58880 to 0.56693, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - 1962s 3s/step - loss: 0.4861 - acc: 0.8577 - val_loss: 0.5905 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.56693\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - 1984s 3s/step - loss: 0.4670 - acc: 0.8623 - val_loss: 0.5761 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.56693\n",
      "Epoch 24/25\n",
      "781/781 [==============================] - 2103s 3s/step - loss: 0.4510 - acc: 0.8664 - val_loss: 0.5486 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.56693 to 0.54857, saving model to /data/ResNet50/ResNet50_20190404_species_weights.h5\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - 2045s 3s/step - loss: 0.4529 - acc: 0.8661 - val_loss: 0.5759 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.54857\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples//batch_size, \n",
    "    class_weight=class_weights, \n",
    "    max_queue_size=batch_size*4,\n",
    "    callbacks=[checkpointer, tboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
